#!/usr/bin/env python3
"""
Oracle850B WebDataset Sharding
–£–ø–∞–∫–æ–≤–∫–∞ –≤ tar-—à–∞—Ä–¥—ã + .idx –∏–Ω–¥–µ–∫—Å
Author: MagistrTheOne|–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä|2025
"""

import os
import json
import tarfile
import argparse
from pathlib import Path
from typing import List, Dict, Any, Iterator
from datetime import datetime
import math


class OracleWebDatasetSharder:
    """–®–∞—Ä–¥–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –≤ WebDataset —Ñ–æ—Ä–º–∞—Ç"""
    
    def __init__(self, output_dir: str = "data/webdataset", 
                 shard_size_mb: int = 512):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.shard_size_bytes = shard_size_mb * 1024 * 1024
        
    def create_shard(self, shard_id: int, texts: List[str], 
                    metadata: Dict[str, Any] = None) -> Path:
        """–°–æ–∑–¥–∞—Ç—å —à–∞—Ä–¥ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤"""
        
        shard_name = f"shard-{shard_id:06d}.tar"
        shard_path = self.output_dir / shard_name
        
        print(f"üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —à–∞—Ä–¥–∞: {shard_name}")
        
        with tarfile.open(shard_path, 'w') as tar:
            for i, text in enumerate(texts):
                # –°–æ–∑–¥–∞—Ç—å –∏–º—è —Ñ–∞–π–ª–∞ –≤ —à–∞—Ä–¥–µ
                filename = f"{i:06d}.txt"
                
                # –î–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –≤ tar
                text_bytes = text.encode('utf-8')
                tarinfo = tarfile.TarInfo(name=filename)
                tarinfo.size = len(text_bytes)
                tarinfo.mtime = datetime.now().timestamp()
                
                tar.addfile(tarinfo, fileobj=io.BytesIO(text_bytes))
        
        # –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å —Ñ–∞–π–ª
        idx_path = shard_path.with_suffix('.idx')
        self._create_index_file(idx_path, texts, metadata)
        
        print(f"‚úÖ –®–∞—Ä–¥ —Å–æ–∑–¥–∞–Ω: {shard_path} ({shard_path.stat().st_size / 1024 / 1024:.1f} MB)")
        return shard_path
    
    def _create_index_file(self, idx_path: Path, texts: List[str], 
                          metadata: Dict[str, Any] = None):
        """–°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å —Ñ–∞–π–ª –¥–ª—è —à–∞—Ä–¥–∞"""
        
        index_data = {
            "shard_info": {
                "total_samples": len(texts),
                "created_at": datetime.now().isoformat(),
                "shard_size_bytes": 0,  # –ë—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–æ
                "metadata": metadata or {}
            },
            "samples": []
        }
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–∂–¥–æ–º —Å—ç–º–ø–ª–µ
        for i, text in enumerate(texts):
            sample_info = {
                "index": i,
                "filename": f"{i:06d}.txt",
                "text_length": len(text),
                "text_preview": text[:100] + "..." if len(text) > 100 else text
            }
            index_data["samples"].append(sample_info)
        
        # –û–±–Ω–æ–≤–∏—Ç—å —Ä–∞–∑–º–µ—Ä —à–∞—Ä–¥–∞
        shard_path = idx_path.with_suffix('.tar')
        if shard_path.exists():
            index_data["shard_info"]["shard_size_bytes"] = shard_path.stat().st_size
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–Ω–¥–µ–∫—Å
        with open(idx_path, 'w', encoding='utf-8') as f:
            json.dump(index_data, f, indent=2, ensure_ascii=False)
    
    def shard_file(self, input_file: Path, split: str = "train") -> List[Path]:
        """–†–∞–∑–±–∏—Ç—å —Ñ–∞–π–ª –Ω–∞ —à–∞—Ä–¥—ã"""
        
        print(f"üîÑ –®–∞—Ä–¥–∏–Ω–≥ —Ñ–∞–π–ª–∞: {input_file}")
        print(f"üìä –†–∞–∑–º–µ—Ä —à–∞—Ä–¥–∞: {self.shard_size_bytes / 1024 / 1024:.1f} MB")
        
        # –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è split
        split_dir = self.output_dir / split
        split_dir.mkdir(exist_ok=True)
        
        shard_paths = []
        current_shard_texts = []
        current_size = 0
        shard_id = 0
        
        with open(input_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                text = line.strip()
                if not text:
                    continue
                
                text_size = len(text.encode('utf-8'))
                
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π —à–∞—Ä–¥
                if (current_size + text_size > self.shard_size_bytes and 
                    current_shard_texts):
                    
                    # –°–æ–∑–¥–∞—Ç—å —Ç–µ–∫—É—â–∏–π —à–∞—Ä–¥
                    shard_path = self._create_shard_in_split(
                        split_dir, shard_id, current_shard_texts, split
                    )
                    shard_paths.append(shard_path)
                    
                    # –ù–∞—á–∞—Ç—å –Ω–æ–≤—ã–π —à–∞—Ä–¥
                    current_shard_texts = []
                    current_size = 0
                    shard_id += 1
                
                current_shard_texts.append(text)
                current_size += text_size
                
                if line_num % 10000 == 0:
                    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {line_num}")
        
        # –°–æ–∑–¥–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞—Ä–¥
        if current_shard_texts:
            shard_path = self._create_shard_in_split(
                split_dir, shard_id, current_shard_texts, split
            )
            shard_paths.append(shard_path)
        
        print(f"‚úÖ –®–∞—Ä–¥–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω: {len(shard_paths)} —à–∞—Ä–¥–æ–≤ —Å–æ–∑–¥–∞–Ω–æ")
        return shard_paths
    
    def _create_shard_in_split(self, split_dir: Path, shard_id: int, 
                             texts: List[str], split: str) -> Path:
        """–°–æ–∑–¥–∞—Ç—å —à–∞—Ä–¥ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ split"""
        
        shard_name = f"shard-{shard_id:06d}.tar"
        shard_path = split_dir / shard_name
        
        with tarfile.open(shard_path, 'w') as tar:
            for i, text in enumerate(texts):
                filename = f"{i:06d}.txt"
                text_bytes = text.encode('utf-8')
                
                tarinfo = tarfile.TarInfo(name=filename)
                tarinfo.size = len(text_bytes)
                tarinfo.mtime = datetime.now().timestamp()
                
                tar.addfile(tarinfo, fileobj=io.BytesIO(text_bytes))
        
        # –°–æ–∑–¥–∞—Ç—å –∏–Ω–¥–µ–∫—Å
        idx_path = shard_path.with_suffix('.idx')
        metadata = {
            "split": split,
            "shard_id": shard_id,
            "source_file": str(input_file)
        }
        self._create_index_file(idx_path, texts, metadata)
        
        return shard_path
    
    def create_manifest(self, split: str, shard_paths: List[Path]) -> Path:
        """–°–æ–∑–¥–∞—Ç—å –º–∞–Ω–∏—Ñ–µ—Å—Ç –¥–ª—è split"""
        
        manifest_path = self.output_dir / f"{split}_manifest.json"
        
        manifest = {
            "split": split,
            "total_shards": len(shard_paths),
            "total_samples": 0,
            "created_at": datetime.now().isoformat(),
            "shards": []
        }
        
        for shard_path in shard_paths:
            # –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–Ω–¥–µ–∫—Å —à–∞—Ä–¥–∞
            idx_path = shard_path.with_suffix('.idx')
            if idx_path.exists():
                with open(idx_path, 'r', encoding='utf-8') as f:
                    shard_info = json.load(f)
                
                shard_manifest = {
                    "shard_path": str(shard_path.relative_to(self.output_dir)),
                    "idx_path": str(idx_path.relative_to(self.output_dir)),
                    "total_samples": shard_info["shard_info"]["total_samples"],
                    "shard_size_bytes": shard_info["shard_info"]["shard_size_bytes"]
                }
                
                manifest["shards"].append(shard_manifest)
                manifest["total_samples"] += shard_manifest["total_samples"]
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–∞–Ω–∏—Ñ–µ—Å—Ç
        with open(manifest_path, 'w', encoding='utf-8') as f:
            json.dump(manifest, f, indent=2, ensure_ascii=False)
        
        print(f"üìã –ú–∞–Ω–∏—Ñ–µ—Å—Ç —Å–æ–∑–¥–∞–Ω: {manifest_path}")
        return manifest_path
    
    def get_shard_info(self, shard_path: Path) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —à–∞—Ä–¥–µ"""
        
        idx_path = shard_path.with_suffix('.idx')
        if not idx_path.exists():
            return {"error": "–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω"}
        
        with open(idx_path, 'r', encoding='utf-8') as f:
            return json.load(f)


def main():
    parser = argparse.ArgumentParser(description="Oracle850B WebDataset Sharding")
    parser.add_argument("--input-file", required=True, help="–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª")
    parser.add_argument("--output-dir", default="data/webdataset", help="–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è")
    parser.add_argument("--split", default="train", help="–ù–∞–∑–≤–∞–Ω–∏–µ split")
    parser.add_argument("--shard-size-mb", type=int, default=512, help="–†–∞–∑–º–µ—Ä —à–∞—Ä–¥–∞ –≤ MB")
    parser.add_argument("--info", help="–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —à–∞—Ä–¥–µ")
    
    args = parser.parse_args()
    
    sharder = OracleWebDatasetSharder(args.output_dir, args.shard_size_mb)
    
    if args.info:
        # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —à–∞—Ä–¥–µ
        shard_path = Path(args.info)
        info = sharder.get_shard_info(shard_path)
        print("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —à–∞—Ä–¥–µ:")
        print(json.dumps(info, indent=2, ensure_ascii=False))
    else:
        # –°–æ–∑–¥–∞—Ç—å —à–∞—Ä–¥—ã
        input_path = Path(args.input_file)
        shard_paths = sharder.shard_file(input_path, args.split)
        
        # –°–æ–∑–¥–∞—Ç—å –º–∞–Ω–∏—Ñ–µ—Å—Ç
        manifest_path = sharder.create_manifest(args.split, shard_paths)
        
        print(f"‚úÖ –®–∞—Ä–¥–∏–Ω–≥ –∑–∞–≤–µ—Ä—à—ë–Ω: {len(shard_paths)} —à–∞—Ä–¥–æ–≤ –≤ {args.split}")


if __name__ == "__main__":
    import io
    main()
