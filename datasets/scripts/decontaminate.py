#!/usr/bin/env python3
"""
Oracle850B Data Decontamination
–°—Ç–æ–ø-–ª–∏—Å—Ç—ã eval, –æ—Ç—á—ë—Ç—ã –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
Author: MagistrTheOne|–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä|2025
"""

import json
import argparse
from pathlib import Path
from typing import List, Dict, Set, Any
from datetime import datetime
import re


class OracleDecontaminator:
    """–î–µ-–∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö Oracle850B"""
    
    def __init__(self, output_dir: str = "data/decontaminated"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # –°—Ç–æ–ø-–ª–∏—Å—Ç—ã –¥–ª—è eval –Ω–∞–±–æ—Ä–æ–≤
        self.eval_stopwords = {
            # GSM8K
            "gsm8k": [
                "jane has", "sarah has", "mike has", "tom has",
                "how many", "what is", "calculate", "solve",
                "math problem", "word problem"
            ],
            
            # MATH
            "math": [
                "prove that", "show that", "find the", "determine",
                "mathematical", "theorem", "lemma", "corollary"
            ],
            
            # HumanEval
            "humaneval": [
                "def ", "function", "return", "python",
                "code", "programming", "algorithm"
            ],
            
            # MMLU
            "mmlu": [
                "which of the following", "what is the",
                "according to", "based on", "the correct answer"
            ],
            
            # Hellaswag
            "hellaswag": [
                "complete the", "finish the", "what happens next",
                "choose the best", "select the"
            ]
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è eval –¥–∞–Ω–Ω—ã—Ö
        self.eval_patterns = {
            "gsm8k": r"(?:jane|sarah|mike|tom).*?(?:how many|what is|calculate)",
            "math": r"(?:prove|show|find|determine).*?(?:theorem|lemma)",
            "humaneval": r"def\s+\w+.*?return",
            "mmlu": r"(?:which of the following|what is the).*?(?:correct answer)",
            "hellaswag": r"(?:complete|finish).*?(?:choose|select)"
        }
    
    def detect_eval_contamination(self, text: str) -> Dict[str, Any]:
        """–û–±–Ω–∞—Ä—É–∂–∏—Ç—å –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—é eval –¥–∞–Ω–Ω—ã–º–∏"""
        
        contamination = {
            "is_contaminated": False,
            "detected_eval": [],
            "confidence_scores": {},
            "matched_patterns": []
        }
        
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞–º
        for eval_name, stopwords in self.eval_stopwords.items():
            matches = []
            for stopword in stopwords:
                if stopword in text_lower:
                    matches.append(stopword)
            
            if matches:
                contamination["detected_eval"].append(eval_name)
                contamination["confidence_scores"][eval_name] = len(matches) / len(stopwords)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        for eval_name, pattern in self.eval_patterns.items():
            if re.search(pattern, text_lower, re.IGNORECASE):
                contamination["matched_patterns"].append(eval_name)
                if eval_name not in contamination["detected_eval"]:
                    contamination["detected_eval"].append(eval_name)
        
        # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –æ–±—â—É—é –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—é
        contamination["is_contaminated"] = len(contamination["detected_eval"]) > 0
        
        return contamination
    
    def calculate_contamination_score(self, text: str) -> float:
        """–í—ã—á–∏—Å–ª–∏—Ç—å –æ–±—â–∏–π —Å–∫–æ—Ä –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏–∏"""
        contamination = self.detect_eval_contamination(text)
        
        if not contamination["is_contaminated"]:
            return 0.0
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ —Å–∫–æ—Ä–æ–≤
        total_score = 0.0
        total_weight = 0.0
        
        for eval_name in contamination["detected_eval"]:
            weight = 1.0  # –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–µ—Å–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö eval
            score = contamination["confidence_scores"].get(eval_name, 0.0)
            
            total_score += weight * score
            total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    def decontaminate_text(self, text: str, threshold: float = 0.3) -> Dict[str, Any]:
        """–î–µ-–∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""
        
        contamination = self.detect_eval_contamination(text)
        contamination_score = self.calculate_contamination_score(text)
        
        should_keep = contamination_score < threshold
        
        result = {
            "original_text": text,
            "is_contaminated": contamination["is_contaminated"],
            "contamination_score": contamination_score,
            "detected_eval": contamination["detected_eval"],
            "matched_patterns": contamination["matched_patterns"],
            "should_keep": should_keep,
            "threshold": threshold,
            "decontaminated_at": datetime.now().isoformat()
        }
        
        return result
    
    def decontaminate_file(self, input_file: Path, output_file: Path = None, 
                          threshold: float = 0.3) -> Dict[str, Any]:
        """–î–µ-–∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è —Ñ–∞–π–ª–∞"""
        
        if output_file is None:
            output_file = self.output_dir / f"decontaminated_{input_file.name}"
        
        print(f"üîÑ –î–µ-–∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è —Ñ–∞–π–ª–∞: {input_file}")
        print(f"üìä –ü–æ—Ä–æ–≥ –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏–∏: {threshold}")
        
        decontaminated_texts = []
        stats = {
            "total_lines": 0,
            "kept_lines": 0,
            "removed_contaminated": 0,
            "contamination_by_eval": {},
            "avg_contamination_score": 0.0
        }
        
        contamination_scores = []
        
        with open(input_file, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                stats["total_lines"] += 1
                
                if line_num % 1000 == 0:
                    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫: {line_num}")
                
                # –î–µ-–∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–∏
                result = self.decontaminate_text(line.strip(), threshold)
                contamination_scores.append(result["contamination_score"])
                
                if result["should_keep"]:
                    decontaminated_texts.append(line.strip())
                    stats["kept_lines"] += 1
                else:
                    stats["removed_contaminated"] += 1
                    
                    # –ü–æ–¥—Å—á–µ—Ç –ø–æ —Ç–∏–ø–∞–º eval
                    for eval_name in result["detected_eval"]:
                        if eval_name not in stats["contamination_by_eval"]:
                            stats["contamination_by_eval"][eval_name] = 0
                        stats["contamination_by_eval"][eval_name] += 1
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å —Å—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏–∏
        if contamination_scores:
            stats["avg_contamination_score"] = sum(contamination_scores) / len(contamination_scores)
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–µ-–∫–æ–Ω—Ç–∞–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        with open(output_file, 'w', encoding='utf-8') as f:
            for text in decontaminated_texts:
                f.write(text + '\n')
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_file = output_file.with_suffix('.stats.json')
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ –î–µ-–∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {stats['kept_lines']}/{stats['total_lines']} —Å—Ç—Ä–æ–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {json.dumps(stats, ensure_ascii=False)}")
        
        return stats
    
    def generate_contamination_report(self, input_files: List[Path], 
                                    output_file: Path = None) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –æ –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏–∏"""
        
        if output_file is None:
            output_file = self.output_dir / "contamination_report.json"
        
        print("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –æ –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏–∏...")
        
        report = {
            "generated_at": datetime.now().isoformat(),
            "files_analyzed": [],
            "summary": {
                "total_files": 0,
                "total_lines": 0,
                "contaminated_lines": 0,
                "contamination_rate": 0.0
            },
            "contamination_by_eval": {},
            "recommendations": []
        }
        
        total_lines = 0
        contaminated_lines = 0
        
        for input_file in input_files:
            print(f"  –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: {input_file}")
            
            file_stats = {
                "file_path": str(input_file),
                "total_lines": 0,
                "contaminated_lines": 0,
                "contamination_rate": 0.0,
                "detected_eval": {}
            }
            
            with open(input_file, 'r', encoding='utf-8') as f:
                for line in f:
                    file_stats["total_lines"] += 1
                    total_lines += 1
                    
                    contamination = self.detect_eval_contamination(line.strip())
                    if contamination["is_contaminated"]:
                        file_stats["contaminated_lines"] += 1
                        contaminated_lines += 1
                        
                        # –ü–æ–¥—Å—á–µ—Ç –ø–æ —Ç–∏–ø–∞–º eval
                        for eval_name in contamination["detected_eval"]:
                            if eval_name not in file_stats["detected_eval"]:
                                file_stats["detected_eval"][eval_name] = 0
                            file_stats["detected_eval"][eval_name] += 1
                            
                            if eval_name not in report["contamination_by_eval"]:
                                report["contamination_by_eval"][eval_name] = 0
                            report["contamination_by_eval"][eval_name] += 1
            
            # –í—ã—á–∏—Å–ª–∏—Ç—å rate –¥–ª—è —Ñ–∞–π–ª–∞
            if file_stats["total_lines"] > 0:
                file_stats["contamination_rate"] = file_stats["contaminated_lines"] / file_stats["total_lines"]
            
            report["files_analyzed"].append(file_stats)
        
        # –û–±–Ω–æ–≤–∏—Ç—å —Å–≤–æ–¥–∫—É
        report["summary"]["total_files"] = len(input_files)
        report["summary"]["total_lines"] = total_lines
        report["summary"]["contaminated_lines"] = contaminated_lines
        if total_lines > 0:
            report["summary"]["contamination_rate"] = contaminated_lines / total_lines
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if report["summary"]["contamination_rate"] > 0.1:
            report["recommendations"].append("–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏–∏ - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è")
        
        if "gsm8k" in report["contamination_by_eval"]:
            report["recommendations"].append("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è GSM8K - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")
        
        if "humaneval" in report["contamination_by_eval"]:
            report["recommendations"].append("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è HumanEval - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–¥ –¥–∞–Ω–Ω—ã–µ")
        
        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á—ë—Ç
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"‚úÖ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file}")
        print(f"üìä –û–±—â–∞—è –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è: {report['summary']['contamination_rate']:.2%}")
        
        return report


def main():
    parser = argparse.ArgumentParser(description="Oracle850B Data Decontamination")
    parser.add_argument("--input-file", help="–í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª")
    parser.add_argument("--input-files", nargs="+", help="–í—Ö–æ–¥–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è –æ—Ç—á—ë—Ç–∞")
    parser.add_argument("--output-file", help="–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª")
    parser.add_argument("--output-dir", default="data/decontaminated", help="–í—ã—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è")
    parser.add_argument("--threshold", type=float, default=0.3, help="–ü–æ—Ä–æ–≥ –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏–∏")
    parser.add_argument("--report", action="store_true", help="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞")
    
    args = parser.parse_args()
    
    decontaminator = OracleDecontaminator(args.output_dir)
    
    if args.report and args.input_files:
        report = decontaminator.generate_contamination_report(
            [Path(f) for f in args.input_files]
        )
        print("‚úÖ –û—Ç—á—ë—Ç –æ –∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
    elif args.input_file:
        input_path = Path(args.input_file)
        output_path = Path(args.output_file) if args.output_file else None
        
        stats = decontaminator.decontaminate_file(
            input_path, output_path, args.threshold
        )
        print(f"‚úÖ –î–µ-–∫–æ–Ω—Ç–∞–º–∏–Ω–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {stats['kept_lines']}/{stats['total_lines']} —Å—Ç—Ä–æ–∫")
    else:
        print("‚ùå –£–∫–∞–∂–∏—Ç–µ --input-file –∏–ª–∏ --input-files —Å --report")


if __name__ == "__main__":
    main()
