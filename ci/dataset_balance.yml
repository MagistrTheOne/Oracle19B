name: Dataset Language Balance

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'datasets/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'datasets/**'

jobs:
  validate-language-balance:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install --upgrade pip

    - name: Check language balance
      run: |
        echo "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ —è–∑—ã–∫–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö..."

        # –§—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —è–∑—ã–∫–∞
        analyze_language() {
          local file="$1"
          if [ ! -f "$file" ]; then
            echo "‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: $file"
            return 0
          fi

          echo "  –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞: $file"

          # –ü–æ–¥—Å—á—ë—Ç —è–∑—ã–∫–æ–≤ —á–µ—Ä–µ–∑ Python
          python3 -c "
          import json, re, sys
          from collections import Counter

          ru_count = 0
          en_count = 0
          total_count = 0

          with open('$file', 'r', encoding='utf-8') as f:
            for line in f:
              try:
                data = json.loads(line.strip())
                tags = data.get('tags', [])
                messages = data.get('messages', [])

                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –ø–æ —Ç–µ–≥–∞–º
                if 'ru' in tags:
                  ru_count += 1
                elif 'en' in tags:
                  en_count += 1

                total_count += 1

                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É (–µ—Å–ª–∏ –Ω–µ—Ç —Ç–µ–≥–æ–≤)
                if 'ru' not in tags and 'en' not in tags and messages:
                  text = ' '.join([msg.get('content', '') for msg in messages])
                  cyrillic_chars = len(re.findall(r'[–∞-—è—ë]', text.lower()))
                  latin_chars = len(re.findall(r'[a-z]', text.lower()))

                  if cyrillic_chars > latin_chars:
                    ru_count += 1
                  elif latin_chars > 0:
                    en_count += 1

              except:
                continue

          if total_count == 0:
            print('  –ü—É—Å—Ç–æ–π —Ñ–∞–π–ª')
            exit(0)

          ru_pct = (ru_count / total_count) * 100
          en_pct = (en_count / total_count) * 100

          print(f'  –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {total_count}')
          print(f'  –†—É—Å—Å–∫–∏–π: {ru_count} ({ru_pct:.1f}%)')
          print(f'  –ê–Ω–≥–ª–∏–π—Å–∫–∏–π: {en_count} ({en_pct:.1f}%)')

          # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ (–¥–æ–ø—É—Å—Ç–∏–º—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω 30-60% –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —è–∑—ã–∫–∞)
          if not (30 <= ru_pct <= 60) and not (30 <= en_pct <= 60):
            print(f'‚ùå –ù–∞—Ä—É—à–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞: RU={ru_pct:.1f}%, EN={en_pct:.1f}%')
            sys.exit(1)

          print('‚úÖ –ë–∞–ª–∞–Ω—Å —è–∑—ã–∫–æ–≤ –≤ –Ω–æ—Ä–º–µ')
          "
        }

        # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
        exit_code=0

        # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –≤ datasets/mix/
        for file in datasets/mix/*.jsonl; do
          if [ -f "$file" ]; then
            echo ""
            echo "üìä –ê–Ω–∞–ª–∏–∑: $(basename "$file")"
            if ! analyze_language "$file"; then
              exit_code=1
            fi
          fi
        done

        # –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –≤ data/ (–µ—Å–ª–∏ –µ—Å—Ç—å)
        for file in data/**/*.jsonl; do
          if [ -f "$file" ]; then
            echo ""
            echo "üìä –ê–Ω–∞–ª–∏–∑: $(basename "$file")"
            if ! analyze_language "$file"; then
              exit_code=1
            fi
          fi
        done

        if [ $exit_code -eq 0 ]; then
          echo ""
          echo "‚úÖ –ë–∞–ª–∞–Ω—Å —è–∑—ã–∫–æ–≤ –≤–æ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –Ω–æ—Ä–º—ã (30-60%)"
        else
          echo ""
          echo "‚ùå –ù–∞—Ä—É—à–µ–Ω–∏–µ –±–∞–ª–∞–Ω—Å–∞ —è–∑—ã–∫–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
          exit 1
        fi

    - name: Generate language report
      run: |
        echo "üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –æ –±–∞–ª–∞–Ω—Å–µ —è–∑—ã–∫–æ–≤..."

        # –°–æ–∑–¥–∞–Ω–∏–µ —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á—ë—Ç–∞
        python3 -c "
        import json, os, re
        from collections import Counter

        def analyze_file(filepath):
          if not os.path.exists(filepath):
            return None

          ru_count, en_count, total = 0, 0, 0

          with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
              try:
                data = json.loads(line.strip())
                tags = data.get('tags', [])

                if 'ru' in tags:
                  ru_count += 1
                elif 'en' in tags:
                  en_count += 1

                total += 1
              except:
                continue

          return {'ru': ru_count, 'en': en_count, 'total': total}

        # –ê–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
        datasets = []
        for root, dirs, files in os.walk('datasets'):
          for file in files:
            if file.endswith('.jsonl'):
              filepath = os.path.join(root, file)
              result = analyze_file(filepath)
              if result:
                datasets.append({
                  'file': filepath,
                  'ru_count': result['ru'],
                  'en_count': result['en'],
                  'total': result['total']
                })

        # –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_ru = sum(d['ru_count'] for d in datasets)
        total_en = sum(d['en_count'] for d in datasets)
        total_all = sum(d['total'] for d in datasets)

        print(f'\\nüìä –°–≤–æ–¥–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Å–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞–º:')
        print(f'  –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {total_all}')
        print(f'  –†—É—Å—Å–∫–∏–π: {total_ru} ({total_ru/total_all*100:.1f}%)')
        print(f'  –ê–Ω–≥–ª–∏–π—Å–∫–∏–π: {total_en} ({total_en/total_all*100:.1f}%)')

        # –î–µ—Ç–∞–ª–∏ –ø–æ —Ñ–∞–π–ª–∞–º
        print(f'\\nüìÅ –î–µ—Ç–∞–ª–∏ –ø–æ —Ñ–∞–π–ª–∞–º:')
        for d in sorted(datasets, key=lambda x: x['total'], reverse=True):
          ru_pct = d['ru_count']/d['total']*100 if d['total'] > 0 else 0
          en_pct = d['en_count']/d['total']*100 if d['total'] > 0 else 0
          print(f'  {os.path.basename(d[\"file\"])}: RU={d[\"ru_count\"]}({ru_pct:.1f}%), EN={d[\"en_count\"]}({en_pct:.1f}%), –í—Å–µ–≥–æ={d[\"total\"]}')

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—â–µ–≥–æ –±–∞–ª–∞–Ω—Å–∞
        if total_all > 0:
          overall_ru_pct = total_ru / total_all * 100
          overall_en_pct = total_en / total_all * 100

          if not (30 <= overall_ru_pct <= 60) or not (30 <= overall_en_pct <= 60):
            print(f'\\n‚ùå –û–±—â–∏–π –±–∞–ª–∞–Ω—Å –Ω–∞—Ä—É—à–µ–Ω: RU={overall_ru_pct:.1f}%, EN={overall_en_pct:.1f}%')
            exit(1)

          print(f'\\n‚úÖ –û–±—â–∏–π –±–∞–ª–∞–Ω—Å —è–∑—ã–∫–æ–≤ –≤ –Ω–æ—Ä–º–µ')
        "

        echo "‚úÖ –û—Ç—á—ë—Ç –æ –±–∞–ª–∞–Ω—Å–µ —è–∑—ã–∫–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω"
