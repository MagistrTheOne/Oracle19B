#!/usr/bin/env python3
"""
Oracle850B Argo DAG Dry-Run
–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –¥–∞–Ω–Ω—ã—Ö –∏ –æ–±—É—á–µ–Ω–∏—è
Author: MagistrTheOne|–ö—Ä–∞—Å–Ω–æ–¥–∞—Ä|2025
"""

import os
import sys
import yaml
import json
import argparse
from pathlib import Path
from typing import Dict, List, Any, Optional


class OracleArgoDAGValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä Argo DAG –¥–ª—è Oracle850B"""
    
    def __init__(self, argo_dir: str = "infra/argo"):
        self.argo_dir = Path(argo_dir)
        self.pipelines = {}
        self.errors = []
        self.warnings = []
    
    def load_pipelines(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å–µ –ø–∞–π–ø–ª–∞–π–Ω—ã Argo"""
        print("üîç –ó–∞–≥—Ä—É–∑–∫–∞ Argo –ø–∞–π–ø–ª–∞–π–Ω–æ–≤...")
        
        pipeline_files = [
            "data-pipeline.yaml",
            "serving-pipeline.yaml", 
            "training-pipeline.yaml"
        ]
        
        for pipeline_file in pipeline_files:
            pipeline_path = self.argo_dir / pipeline_file
            if pipeline_path.exists():
                try:
                    with open(pipeline_path, 'r', encoding='utf-8') as f:
                        pipeline = yaml.safe_load(f)
                    
                    self.pipelines[pipeline_file] = pipeline
                    print(f"  ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {pipeline_file}")
                    
                except Exception as e:
                    error_msg = f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {pipeline_file}: {e}"
                    self.errors.append(error_msg)
                    print(f"  ‚ùå {error_msg}")
            else:
                warning_msg = f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pipeline_file}"
                self.warnings.append(warning_msg)
                print(f"  ‚ö†Ô∏è  {warning_msg}")
        
        return len(self.errors) == 0
    
    def validate_data_pipeline(self) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è data-pipeline.yaml...")
        
        if "data-pipeline.yaml" not in self.pipelines:
            self.errors.append("data-pipeline.yaml –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        pipeline = self.pipelines["data-pipeline.yaml"]
        success = True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        required_fields = ["apiVersion", "kind", "metadata", "spec"]
        for field in required_fields:
            if field not in pipeline:
                self.errors.append(f"data-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {field}")
                success = False
        
        if not success:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ WorkflowTemplate
        if pipeline.get("kind") != "WorkflowTemplate":
            self.errors.append("data-pipeline: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å WorkflowTemplate")
            success = False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —à–∞–≥–æ–≤ –ø–∞–π–ø–ª–∞–π–Ω–∞
        spec = pipeline.get("spec", {})
        templates = spec.get("templates", [])
        
        required_steps = [
            "ingest-data",
            "clean-data", 
            "decontaminate-data",
            "shard-data",
            "validate-data"
        ]
        
        step_names = [template.get("name") for template in templates]
        
        for step in required_steps:
            if step not in step_names:
                self.errors.append(f"data-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —à–∞–≥ {step}")
                success = False
        
        if success:
            print("  ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ data-pipeline –≤–∞–ª–∏–¥–Ω–∞")
            print(f"  üìä –®–∞–≥–æ–≤ –≤ –ø–∞–π–ø–ª–∞–π–Ω–µ: {len(templates)}")
            print(f"  üîÑ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: {len(spec.get('workflows', []))}")
        
        return success
    
    def validate_serving_pipeline(self) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å–µ—Ä–≤–∏–Ω–≥–∞"""
        print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è serving-pipeline.yaml...")
        
        if "serving-pipeline.yaml" not in self.pipelines:
            self.errors.append("serving-pipeline.yaml –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        pipeline = self.pipelines["serving-pipeline.yaml"]
        success = True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        required_fields = ["apiVersion", "kind", "metadata", "spec"]
        for field in required_fields:
            if field not in pipeline:
                self.errors.append(f"serving-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {field}")
                success = False
        
        if not success:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ WorkflowTemplate
        if pipeline.get("kind") != "WorkflowTemplate":
            self.errors.append("serving-pipeline: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å WorkflowTemplate")
            success = False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤
        spec = pipeline.get("spec", {})
        templates = spec.get("templates", [])
        
        if not templates:
            self.errors.append("serving-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —à–∞–±–ª–æ–Ω—ã")
            success = False
        else:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –≤ —à–∞–±–ª–æ–Ω–∞—Ö
            container_found = False
            for template in templates:
                container = template.get("container")
                if container:
                    container_found = True
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—Ä–∞–∑–∞
                    image = container.get("image")
                    if not image or "oracle850b" not in image:
                        self.warnings.append("serving-pipeline: –æ–±—Ä–∞–∑ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç oracle850b")
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
                    resources = container.get("resources", {})
                    if not resources:
                        self.warnings.append("serving-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ä–µ—Å—É—Ä—Å—ã")
            
            if not container_found:
                self.warnings.append("serving-pipeline: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –≤ —à–∞–±–ª–æ–Ω–∞—Ö")
        
        if success:
            print("  ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ serving-pipeline –≤–∞–ª–∏–¥–Ω–∞")
            print(f"  üìã –®–∞–±–ª–æ–Ω–æ–≤: {len(templates)}")
            print(f"  üê≥ –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {container_found}")
        
        return success
    
    def validate_training_pipeline(self) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—É—á–µ–Ω–∏—è"""
        print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è training-pipeline.yaml...")
        
        if "training-pipeline.yaml" not in self.pipelines:
            self.errors.append("training-pipeline.yaml –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
        
        pipeline = self.pipelines["training-pipeline.yaml"]
        success = True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        required_fields = ["apiVersion", "kind", "metadata", "spec"]
        for field in required_fields:
            if field not in pipeline:
                self.errors.append(f"training-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ {field}")
                success = False
        
        if not success:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ WorkflowTemplate
        if pipeline.get("kind") != "WorkflowTemplate":
            self.errors.append("training-pipeline: –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å WorkflowTemplate")
            success = False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤
        spec = pipeline.get("spec", {})
        templates = spec.get("templates", [])
        
        if not templates:
            self.errors.append("training-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —à–∞–±–ª–æ–Ω—ã")
            success = False
        else:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –≤ —à–∞–±–ª–æ–Ω–∞—Ö
            container_found = False
            for template in templates:
                container = template.get("container")
                if container:
                    container_found = True
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
                    env = container.get("env", [])
                    required_env = [
                        "MODEL_NAME",
                        "TRAINING_DATA_PATH", 
                        "CHECKPOINT_PATH"
                    ]
                    
                    env_names = [e.get("name") for e in env]
                    for req_env in required_env:
                        if req_env not in env_names:
                            self.warnings.append(f"training-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è {req_env}")
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤
                    resources = container.get("resources", {})
                    if not resources:
                        self.warnings.append("training-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ä–µ—Å—É—Ä—Å—ã")
                    else:
                        limits = resources.get("limits", {})
                        if "nvidia.com/gpu" not in limits:
                            self.warnings.append("training-pipeline: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç GPU")
            
            if not container_found:
                self.warnings.append("training-pipeline: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –≤ —à–∞–±–ª–æ–Ω–∞—Ö")
        
        if success:
            print("  ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ training-pipeline –≤–∞–ª–∏–¥–Ω–∞")
            print(f"  üìã –®–∞–±–ª–æ–Ω–æ–≤: {len(templates)}")
            print(f"  üê≥ –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {container_found}")
        
        return success
    
    def validate_dependencies(self) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –º–µ–∂–¥—É –ø–∞–π–ø–ª–∞–π–Ω–∞–º–∏"""
        print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π...")
        
        success = True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        pipeline_order = [
            "data-pipeline.yaml",
            "training-pipeline.yaml", 
            "serving-pipeline.yaml"
        ]
        
        for i, pipeline_file in enumerate(pipeline_order):
            if pipeline_file not in self.pipelines:
                self.warnings.append(f"–ü–∞–π–ø–ª–∞–π–Ω {pipeline_file} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
                continue
            
            pipeline = self.pipelines[pipeline_file]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata = pipeline.get("metadata", {})
            labels = metadata.get("labels", {})
            
            if "pipeline-stage" not in labels:
                self.warnings.append(f"{pipeline_file}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç pipeline-stage")
            else:
                stage = labels["pipeline-stage"]
                expected_stage = ["data", "training", "serving"][i]
                if stage != expected_stage:
                    self.warnings.append(f"{pipeline_file}: –Ω–µ–≤–µ—Ä–Ω—ã–π pipeline-stage {stage}, –æ–∂–∏–¥–∞–µ—Ç—Å—è {expected_stage}")
        
        if success:
            print("  ‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤–∞–ª–∏–¥–Ω—ã")
        
        return success
    
    def validate_kubernetes_syntax(self) -> bool:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ Kubernetes"""
        print("\nüîç –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ Kubernetes...")
        
        success = True
        
        for pipeline_file, pipeline in self.pipelines.items():
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            required_top_level = ["apiVersion", "kind", "metadata"]
            
            for field in required_top_level:
                if field not in pipeline:
                    self.errors.append(f"{pipeline_file}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç {field}")
                    success = False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata = pipeline.get("metadata", {})
            if "name" not in metadata:
                self.errors.append(f"{pipeline_file}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç metadata.name")
                success = False
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
            spec = pipeline.get("spec", {})
            if not spec:
                self.errors.append(f"{pipeline_file}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç spec")
                success = False
        
        if success:
            print("  ‚úÖ –°–∏–Ω—Ç–∞–∫—Å–∏—Å Kubernetes –≤–∞–ª–∏–¥–µ–Ω")
        
        return success
    
    def generate_report(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        report = {
            "timestamp": "2024-12-19T00:00:00Z",
            "validator": "OracleArgoDAGValidator",
            "version": "1.0",
            "summary": {
                "total_pipelines": len(self.pipelines),
                "errors": len(self.errors),
                "warnings": len(self.warnings),
                "success": len(self.errors) == 0
            },
            "pipelines": list(self.pipelines.keys()),
            "errors": self.errors,
            "warnings": self.warnings,
            "recommendations": [
                "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –ø–∞–π–ø–ª–∞–π–Ω—ã –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏",
                "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –ª–∏–º–∏—Ç—ã –¥–ª—è production",
                "–î–æ–±–∞–≤—å—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ",
                "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ retry –ø–æ–ª–∏—Ç–∏–∫–∏ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —à–∞–≥–æ–≤"
            ]
        }
        
        return report
    
    def run_full_validation(self) -> bool:
        """–ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤"""
        print("üöÄ Oracle850B Argo DAG Validation")
        print("=" * 50)
        
        success = True
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤
        if not self.load_pipelines():
            success = False
        
        # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è data-pipeline
        if not self.validate_data_pipeline():
            success = False
        
        # 3. –í–∞–ª–∏–¥–∞—Ü–∏—è serving-pipeline
        if not self.validate_serving_pipeline():
            success = False
        
        # 4. –í–∞–ª–∏–¥–∞—Ü–∏—è training-pipeline
        if not self.validate_training_pipeline():
            success = False
        
        # 5. –í–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        if not self.validate_dependencies():
            success = False
        
        # 6. –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
        if not self.validate_kubernetes_syntax():
            success = False
        
        # 7. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        report = self.generate_report()
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
        report_file = Path("argo_validation_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nüìã –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")
        
        if success:
            print("\n‚úÖ –í—Å–µ –ø–∞–π–ø–ª–∞–π–Ω—ã –≤–∞–ª–∏–¥–Ω—ã!")
        else:
            print(f"\n‚ùå –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: {len(self.errors)}")
            print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π: {len(self.warnings)}")
        
        return success


def main():
    parser = argparse.ArgumentParser(description="Oracle850B Argo DAG Validator")
    parser.add_argument("--argo-dir", default="infra/argo", help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å Argo —Ñ–∞–π–ª–∞–º–∏")
    parser.add_argument("--data-only", action="store_true", help="–¢–æ–ª—å–∫–æ data-pipeline")
    parser.add_argument("--serving-only", action="store_true", help="–¢–æ–ª—å–∫–æ serving-pipeline")
    parser.add_argument("--training-only", action="store_true", help="–¢–æ–ª—å–∫–æ training-pipeline")
    parser.add_argument("--report", action="store_true", help="–¢–æ–ª—å–∫–æ –æ—Ç—á–µ—Ç")
    
    args = parser.parse_args()
    
    validator = OracleArgoDAGValidator(args.argo_dir)
    
    if args.data_only:
        success = validator.load_pipelines() and validator.validate_data_pipeline()
    elif args.serving_only:
        success = validator.load_pipelines() and validator.validate_serving_pipeline()
    elif args.training_only:
        success = validator.load_pipelines() and validator.validate_training_pipeline()
    elif args.report:
        validator.load_pipelines()
        report = validator.generate_report()
        print(json.dumps(report, indent=2, ensure_ascii=False))
        success = True
    else:
        success = validator.run_full_validation()
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()
